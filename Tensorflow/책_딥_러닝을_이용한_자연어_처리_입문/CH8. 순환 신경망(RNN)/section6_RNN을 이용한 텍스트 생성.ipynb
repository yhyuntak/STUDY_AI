{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48e5d4f",
   "metadata": {},
   "source": [
    "다 대 일(many-to-one) 구조의 RNN을 사용하여 문맥을 반영해서 텍스트를 생성하는 모델을 만들어보자!\n",
    "\n",
    "# 1. RNN을 이용하여 텍스트 생성하기\n",
    "---\n",
    "\n",
    "예를 들어서 '경마장에 있는 말이 뛰고 있다'와 '그의 말이 법이다'와 '가는 말이 고와야 오는 말이 곱다'라는 세 가지 문장이 있다고 해보자. 모델이 문맥을 학습할 수 있도록, 전체 문장의 앞의 단어들을 전부 고려하여 학습하도록 데이터를 재구성한다면 아래와 같이 총 11개의 샘플이 구성된다. 이 얘기는 앞서 [section 5의 RNN 언어 모델](https://github.com/yhyuntak/STUDY_AI/blob/main/Tensorflow/%E1%84%8E%E1%85%A2%E1%86%A8_%E1%84%83%E1%85%B5%E1%86%B8_%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5_%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5_%E1%84%8B%E1%85%B5%E1%86%B8%E1%84%86%E1%85%AE%E1%86%AB/CH8.%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D(RNN)/section5_RNN%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8.ipynb)에서 **교사 강요(teacher forcing)**의 방식으로 학습한다고 배웠다. 현재 시점 t의 단어 하나를 예측하기 위해서 t-1 까지의 모든 시점이 사용되는 것이 포인트다. \n",
    "\n",
    "![그림 1](./images/section6/그림_1.png)\n",
    "\n",
    "## 1) 데이터에 대한 이해와 전처리\n",
    "\n",
    "먼저 예제로 언급한 3개의 한국어 문장을 변수에 저장하자. 그리고 Tokenizer()로 단어 집합을 생성하고 크기를 확인해보자. 단어 집합의 크기를 저장할 때는 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만, 패딩을 위한 0을 고려하여 +1을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614032c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장들 : \n",
      "경마장에 있는 말이 뛰고 있다\n",
      "\n",
      "그의 말이 법이다\n",
      "\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "--------------------\n",
      "토크나이저의 정수 인코딩 :  {'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n",
      "--------------------\n",
      "단어 집합의 크기 : 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\"\n",
    "print(\"문장들 : \")\n",
    "print(text)\n",
    "print(\"--\"*10)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "print('토크나이저의 정수 인코딩 : ',tokenizer.word_index)\n",
    "print(\"--\"*10)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 위한 0을 고려해 +1을 하기.\n",
    "print('단어 집합의 크기 : %d' % vocab_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d477f4f",
   "metadata": {},
   "source": [
    "#### 이제 훈련 데이터를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7125dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n",
      "샘플들 :  [[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0] # 문장의 단어들을 인덱스화\n",
    "    for i in range(1, len(encoded)):\n",
    "        # 표처럼 만들기 위해서 다음과 같이 코딩\n",
    "        sequence = encoded[:i+1] \n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))\n",
    "print('샘플들 : ',sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3f8e0",
   "metadata": {},
   "source": [
    "위의 데이터는 아직 레이블로 사용될 단어를 분리하지 않은 훈련 데이터이다. [2, 3]은 [경마장에, 있는]에 해당되며 [2, 3, 1]은 [경마장에, 있는, 말이]에 해당된다. 전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 한다.\n",
    "\n",
    "우선 전체 샘플에 대해서 길이를 일치시켜 준다. 가장 긴 샘플의 길이를 기준으로 한다. 현재 육안으로 봤을 때, 길이가 가장 긴 샘플은 [8, 1, 9, 10, 1, 11]이고 길이는 6이다. 이를 코드로는 다음과 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3895e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940277b",
   "metadata": {},
   "source": [
    "전체 훈련 데이터에서 가장 긴 샘플의 길이가 6임을 확인했다. 전체 샘플의 길이를 6으로 패딩하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc80a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 전 샘플들 :\n",
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n",
      "--------------------\n",
      "패딩 후 샘플들 :\n",
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"패딩 전 샘플들 :\")\n",
    "print(sequences)\n",
    "print(\"--\"*10)\n",
    "sequences = pad_sequences(sequences,maxlen=max_len,padding='pre')\n",
    "\n",
    "print(\"패딩 후 샘플들 :\")\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce23173",
   "metadata": {},
   "source": [
    "길이가 6보다 짧은 모든 샘플에 대해서 앞에 0을 채워서 모든 샘플의 길이를 6으로 바꿨다. 이제 각 샘플의 마지막 단어를 레이블로 분리하자. 레이블의 분리는 Numpy를 이용해서 가능하다. 리스트의 마지막 값을 제외하고 저장한 것은 X, 리스트의 마지막 값만 저장한 것은 y. 이는 레이블에 해당된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10cab034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 :\n",
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n",
      "--------------------\n",
      "정답 데이터 :\n",
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "print(\"입력 데이터 :\")\n",
    "print(X)\n",
    "print(\"--\"*10)\n",
    "print(\"정답 데이터 :\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9930b8",
   "metadata": {},
   "source": [
    "\n",
    "RNN 모델에 훈련 데이터를 훈련 시키기 위해 정답 레이블에 대해서 원-핫 인코딩을 적용하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0788c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y,num_classes = vocab_size)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28380839",
   "metadata": {},
   "source": [
    "아, 입력 데이터에는 원-핫 인코딩을 안하는 구나..?\n",
    "\n",
    "## 2) 모델 설계하기\n",
    "\n",
    "RNN 모델에 데이터를 훈련시키도록 하자. \n",
    "\n",
    "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 32이고 다 대 일 구조의 RNN을 사용한다. 전결합층(Fully Connected Layer)을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계한다. 해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델이다. 다중 클래스 분류 문제의 경우, 출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용하여 200 에포크를 수행한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a14e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.4682 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4564 - accuracy: 0.2727 - 8ms/epoch - 8ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4447 - accuracy: 0.2727 - 5ms/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4328 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4208 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4085 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.3959 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3829 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3694 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3553 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3406 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3252 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3091 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.2921 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2742 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2553 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.2354 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2146 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.1927 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1697 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.1458 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.1209 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.0951 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0685 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.0413 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.0135 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 1.9854 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9572 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9291 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9013 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.8741 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.8476 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8221 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.7977 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.7743 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.7521 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.7309 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.7105 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.6908 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.6715 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.6525 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.6335 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.6142 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.5947 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.5747 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.5543 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.5334 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.5120 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.4901 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.4680 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.4455 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.4229 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.4001 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.3773 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.3546 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.3319 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.3094 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.2872 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.2652 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.2437 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.2225 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.2017 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.1814 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.1615 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.1420 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.1228 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.1039 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.0852 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.0667 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.0484 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.0302 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.0120 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 0.9940 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 0.9761 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 0.9583 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 0.9407 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 0.9234 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 0.9062 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 0.8893 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.8727 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.8563 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.8401 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.8242 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.8085 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.7930 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.7778 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.7627 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.7478 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.7332 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.7187 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.7044 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.6904 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.6766 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.6630 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.6496 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.6365 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.6236 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.6109 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.5984 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.5862 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.5742 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.5624 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.5508 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.5394 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.5283 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.5174 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.5067 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.4962 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.4860 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.4759 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.4661 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.4565 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.4470 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.4378 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.4288 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.4199 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.4113 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.4028 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.3945 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.3864 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.3785 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.3707 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.3631 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.3557 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.3484 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.3413 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.3343 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.3275 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.3208 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.3143 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.3079 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.3016 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.2955 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.2895 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.2836 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.2779 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.2722 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.2667 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.2613 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.2561 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.2509 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.2458 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.2409 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.2360 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.2313 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.2267 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.2221 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.2177 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.2133 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2091 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2049 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2008 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.1930 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.1892 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.1854 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.1782 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.1747 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.1713 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.1680 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.1647 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.1616 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.1585 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.1554 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.1524 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.1495 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.1467 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1439 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.1412 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.1385 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1359 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.1334 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1309 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1285 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1262 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1238 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1216 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1194 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1172 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1151 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1131 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1111 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1091 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1072 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1053 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1035 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1017 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.0999 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.0982 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.0965 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.0949 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.0933 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.0917 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.0902 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.0887 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.0873 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.0858 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.0844 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.0831 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)\n",
    "\n",
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2f2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))\n",
    "\n",
    "print(sentence_generation(model, tokenizer, '그의 말이', 1))\n",
    "\n",
    "print(sentence_generation(model, tokenizer, '가는', 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddb34d",
   "metadata": {},
   "source": [
    "앞의 문맥을 기준으로 '말이' 라는 단어 다음에 나올 단어를 기존의 훈련 데이터와 일치하게 예측함을 보여준다. 이 모델은 충분한 훈련 데이터를 갖고 있지 못하므로 위에서 문장의 길이에 맞게 적절하게 예측해야하는 횟수 4, 2, 5를 각각 인자값으로 주었다. 이 이상의 숫자를 주면 기계는 '있다', '법이다', '곱다' 다음에 나오는 단어가 무엇인지 배운 적이 없으므로 임의 예측을 하게 된다.\n",
    "\n",
    "이번에는 더 많은 훈련 데이터를 가지고 실습해보자.\n",
    "\n",
    "<br/><br/>\n",
    "# 2. LSTM을 이용하여 텍스트 생성하기\n",
    "---\n",
    "\n",
    "이번에는 LSTM을 통해 보다 많은 데이터로 텍스트를 생성해보겠다.\n",
    "\n",
    "## 1) 데이터에 대한 이해와 전처리\n",
    "\n",
    "사용할 데이터는 뉴욕 타임즈 기사의 제목이다. 아래의 링크에서 ArticlesApril2018.csv 데이터를 다운로드하자.\n",
    "파일 다운로드 링크 : https://www.kaggle.com/aashita/nyt-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da75a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "df = pd.read_csv(\"./data/ArticlesApril2018.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4638cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324 entries, 0 to 1323\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   articleID         1324 non-null   object\n",
      " 1   articleWordCount  1324 non-null   int64 \n",
      " 2   byline            1324 non-null   object\n",
      " 3   documentType      1324 non-null   object\n",
      " 4   headline          1324 non-null   object\n",
      " 5   keywords          1324 non-null   object\n",
      " 6   multimedia        1324 non-null   int64 \n",
      " 7   newDesk           1324 non-null   object\n",
      " 8   printPage         1324 non-null   int64 \n",
      " 9   pubDate           1324 non-null   object\n",
      " 10  sectionName       1324 non-null   object\n",
      " 11  snippet           1324 non-null   object\n",
      " 12  source            1324 non-null   object\n",
      " 13  typeOfMaterial    1324 non-null   object\n",
      " 14  webURL            1324 non-null   object\n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 155.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3f2b1",
   "metadata": {},
   "source": [
    "데이터프레임을 확인해보니, 전부 null 값이 없다. \n",
    "\n",
    "이번 예제에선 제목에 해당하는 headline을 사용할 것이므로, headline 열 데이터를 확인해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1a8b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Former N.F.L. Cheerleaders’ Settlement Offer: ...\n",
       "1    E.P.A. to Unveil a New Rule. Its Effect: Less ...\n",
       "2                              The New Noma, Explained\n",
       "3                                              Unknown\n",
       "4                                              Unknown\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c2d97",
   "metadata": {},
   "source": [
    "Unknown 이란 값이 존재하는 것을 보았다. 제목이 Unknown이라니.. 좀 이상한 것 같으니 값들의 개수를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ff4bd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown                                                                        110\n",
       "Variety: Acrostic                                                                3\n",
       "Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell      1\n",
       "As Facebook Loses Luster, Tech Stocks Await Fallout                              1\n",
       "This Many                                                                        1\n",
       "                                                                              ... \n",
       "Did Outsiders Make 911 Calls? A Fear Born of Brooklyn Gentrification             1\n",
       "Childhood Fears No Parent Can Allay                                              1\n",
       "For Bannon, Tariffs Are Test of Trump’s Beliefs                                  1\n",
       "The Failures of Anti-Trumpism                                                    1\n",
       "There Is Nothin’ Like a Tune                                                     1\n",
       "Name: headline, Length: 1213, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0566c",
   "metadata": {},
   "source": [
    "무려 Unknown 데이터가 110개나 있다. headline의 데이터 수가 1324인데, 110이면 거의 10%에 해당하는 수준의 결측 값이다. \n",
    "따라서 이 unknown 값을 제외하고 headline 값들을 추출하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3466eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측 값을 제거한 headline의 개수 :  1214\n"
     ]
    }
   ],
   "source": [
    "headline = [title for title in df['headline'] if title != 'Unknown']\n",
    "print(\"결측 값을 제거한 headline의 개수 : \",len(headline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003a689",
   "metadata": {},
   "source": [
    "이제 본격적으로 데이터 전처리를 수행한다. 여기서 선택한 전처리는 구두점 제거와 단어의 소문자화이다. 전처리를 수행하고, 다시 샘플 5개를 출력하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed5b133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(arr):\n",
    "    preprocessed_sentence = arr.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    # 구두점 제거와 동시에 소문자화\n",
    "    # punctuation에는 ASCII 코드에서 구두점(쉼표, 온점, 따옴표 등) 꾸러미가 들어있다.\n",
    "    return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [preprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6fa86",
   "metadata": {},
   "source": [
    "기존의 출력과 비교하면 모든 단어들이 소문자화되었으며 N.F.L.이나 Cheerleaders’ 등과 같이 기존에 구두점이 붙어있던 단어들에서 구두점이 제거되었다. 그러나 Chapter 2의 section 1에서 배웠듯이, 구두점들을 무조건 삭제하는 것은 옳지 않다. 따라서 원래는 nltk 라이브러리를 이용해서 토큰화를 하는 것이 맞다. 일단은 책의 예시를 그대로 따라가보자.\n",
    "\n",
    "이제 단어 집합(vocabulary)을 만들고 크기를 확인하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71d31091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 :  3494\n",
      "빈도수 상위 10개의 정수 인덱스 :  ['the', 'a', 'to', 'of', 'in', 'for', 'and', 'is', 'on', 'with']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index)+1 # \n",
    "print(\"단어 집합의 크기 : \",vocab_size)\n",
    "print(\"빈도수 상위 10개의 정수 인덱스 : \", [ voca for voca,num in  tokenizer.word_index.items() if num <= 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273f3c7",
   "metadata": {},
   "source": [
    "참고로 정수 인덱스는 단어의 빈도수가 높을수록 1에 가깝다. 관사나 전치사가 제일 많은 빈도수를 차지하는 것을 볼 수 있다.\n",
    "\n",
    "이제 하나의 문장을 제일 위 그림의 표처럼 쪼개서 학습 데이터를 생성하도록 하자. 시퀀스를 2개 3개 ... 계속 붙여나가면서 생성하고 크기를 맞추기 위해 zero padding을 한 후, 제일 마지막 column을 y로 나머지를 X로 사용할 것이다. 왜냐하면 하나의 단어를 예측하기 위해서 이전 시점까지의 모든 데이터를 사용할 것이기 때문이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8e9c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 5개 :  [[99, 269], [99, 269, 371], [99, 269, 371, 1115], [99, 269, 371, 1115, 582], [99, 269, 371, 1115, 582, 52]]\n",
      "샘플 데이터의 최대 길이 :  24\n",
      "제로 패딩 추가한 데이터 5개 : \n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   99  269  371 1115  582]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   99  269  371 1115  582   52]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "먼저 한 문장을 여러 시퀀스로 만들어주자.\n",
    "\"\"\"\n",
    "sequences  = []\n",
    "for sentence in preprocessed_headline :\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0] # 항상 list 형식으로 문장을 사용해야한다.\n",
    "    for i in range(1,len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "print(\"데이터 5개 : \",sequences[:5])\n",
    "\n",
    "\"\"\"\n",
    "길이가 가장 긴 데이터의 길이를 찾자.\n",
    "\"\"\"\n",
    "max_len = max(len(temp) for temp in sequences)\n",
    "print(\"샘플 데이터의 최대 길이 : \",max_len)\n",
    "\n",
    "\"\"\"\n",
    "값들 앞에 제로 패딩을 추가하자.\n",
    "\"\"\"\n",
    "sequences = pad_sequences(sequences,maxlen = max_len, padding='pre')\n",
    "print(\"제로 패딩 추가한 데이터 5개 : \")\n",
    "print(sequences[:5])\n",
    "\n",
    "\"\"\"\n",
    "입력 데이터 X, 정답 데이터 y 생성\n",
    "\"\"\"\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "\"\"\"\n",
    "정답 데이터 y에 원-핫 인코딩 적용\n",
    "\"\"\"\n",
    "y = to_categorical(y,num_classes = vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca35a1b",
   "metadata": {},
   "source": [
    "## 2) 모델 설계하기\n",
    "\n",
    "이제 다음 조건의 LSTM 모델을 설계해보자.\n",
    "\n",
    "* 하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 128 \n",
    "* 다 대 일 구조의 LSTM을 사용 \n",
    "* 전결합층(Fully Connected Layer)을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계\n",
    "* 해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델임을 고려해 손실함수, 활성화 함수 설계\n",
    "* Epoch = 100 (원래 책에선 200이라고 나와있지만, 시간을 절약하기 위해 100으로 줄임)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9f7832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 2s 4ms/step - loss: 7.6459 - accuracy: 0.0288\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 7.1166 - accuracy: 0.0306\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.9722 - accuracy: 0.0343\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.8435 - accuracy: 0.0408\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.6864 - accuracy: 0.0454\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.5102 - accuracy: 0.0472\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.3179 - accuracy: 0.0532\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 6.1192 - accuracy: 0.0588\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.9200 - accuracy: 0.0634\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.7295 - accuracy: 0.0666\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.5499 - accuracy: 0.0727\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.3819 - accuracy: 0.0811\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.2253 - accuracy: 0.0830\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 5.0723 - accuracy: 0.0920\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.9279 - accuracy: 0.1010\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.7888 - accuracy: 0.1100\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.6586 - accuracy: 0.1237\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.5292 - accuracy: 0.1387\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.4061 - accuracy: 0.1512\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.2844 - accuracy: 0.1674\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.1683 - accuracy: 0.1843\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 4.0566 - accuracy: 0.2029\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.9441 - accuracy: 0.2209\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.8369 - accuracy: 0.2366\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.7359 - accuracy: 0.2548\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.6328 - accuracy: 0.2718\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.5363 - accuracy: 0.2877\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.4431 - accuracy: 0.3023\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.3525 - accuracy: 0.3213\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.2637 - accuracy: 0.3381\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.1778 - accuracy: 0.3590\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.0947 - accuracy: 0.3743\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 3.0190 - accuracy: 0.3866\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.9390 - accuracy: 0.4007\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.8650 - accuracy: 0.4134\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.7946 - accuracy: 0.4287\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.7237 - accuracy: 0.4488\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.6589 - accuracy: 0.4579\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.5935 - accuracy: 0.4656\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.5311 - accuracy: 0.4780\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.4694 - accuracy: 0.4966\n",
      "Epoch 42/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.4088 - accuracy: 0.5088\n",
      "Epoch 43/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.3516 - accuracy: 0.5186\n",
      "Epoch 44/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.2972 - accuracy: 0.5279\n",
      "Epoch 45/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.2425 - accuracy: 0.5416\n",
      "Epoch 46/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.1903 - accuracy: 0.5540\n",
      "Epoch 47/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.1395 - accuracy: 0.5629\n",
      "Epoch 48/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.0881 - accuracy: 0.5732\n",
      "Epoch 49/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 2.0450 - accuracy: 0.5827\n",
      "Epoch 50/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.9935 - accuracy: 0.5927\n",
      "Epoch 51/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.9461 - accuracy: 0.6046\n",
      "Epoch 52/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.9023 - accuracy: 0.6110\n",
      "Epoch 53/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.8575 - accuracy: 0.6225\n",
      "Epoch 54/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.8162 - accuracy: 0.6298\n",
      "Epoch 55/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.7728 - accuracy: 0.6380\n",
      "Epoch 56/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.7304 - accuracy: 0.6462\n",
      "Epoch 57/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.6930 - accuracy: 0.6585\n",
      "Epoch 58/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.6538 - accuracy: 0.6630\n",
      "Epoch 59/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.6148 - accuracy: 0.6718\n",
      "Epoch 60/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.5808 - accuracy: 0.6799\n",
      "Epoch 61/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.5403 - accuracy: 0.6892\n",
      "Epoch 62/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.5088 - accuracy: 0.6995\n",
      "Epoch 63/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.4712 - accuracy: 0.7056\n",
      "Epoch 64/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.4375 - accuracy: 0.7142\n",
      "Epoch 65/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.4046 - accuracy: 0.7210\n",
      "Epoch 66/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.3721 - accuracy: 0.7256\n",
      "Epoch 67/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.3412 - accuracy: 0.7333\n",
      "Epoch 68/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.3081 - accuracy: 0.7410\n",
      "Epoch 69/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.2778 - accuracy: 0.7441\n",
      "Epoch 70/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.2461 - accuracy: 0.7521\n",
      "Epoch 71/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.2203 - accuracy: 0.7573\n",
      "Epoch 72/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.1912 - accuracy: 0.7632\n",
      "Epoch 73/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.1622 - accuracy: 0.7705\n",
      "Epoch 74/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.1361 - accuracy: 0.7727\n",
      "Epoch 75/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.1081 - accuracy: 0.7816\n",
      "Epoch 76/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.0838 - accuracy: 0.7859\n",
      "Epoch 77/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.0577 - accuracy: 0.7903\n",
      "Epoch 78/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.0333 - accuracy: 0.7944\n",
      "Epoch 79/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 1.0115 - accuracy: 0.8026\n",
      "Epoch 80/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.9850 - accuracy: 0.8057\n",
      "Epoch 81/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.9653 - accuracy: 0.8079\n",
      "Epoch 82/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.9398 - accuracy: 0.8142\n",
      "Epoch 83/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.9194 - accuracy: 0.8183\n",
      "Epoch 84/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.8979 - accuracy: 0.8211\n",
      "Epoch 85/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.8774 - accuracy: 0.8265\n",
      "Epoch 86/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.8572 - accuracy: 0.8290\n",
      "Epoch 87/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.8370 - accuracy: 0.8374\n",
      "Epoch 88/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.8187 - accuracy: 0.8398\n",
      "Epoch 89/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7992 - accuracy: 0.8430\n",
      "Epoch 90/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7816 - accuracy: 0.8478\n",
      "Epoch 91/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7626 - accuracy: 0.8503\n",
      "Epoch 92/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7443 - accuracy: 0.8521\n",
      "Epoch 93/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7315 - accuracy: 0.8540\n",
      "Epoch 94/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.7130 - accuracy: 0.8577\n",
      "Epoch 95/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6966 - accuracy: 0.8616\n",
      "Epoch 96/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6832 - accuracy: 0.8643\n",
      "Epoch 97/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.8684\n",
      "Epoch 98/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.8697\n",
      "Epoch 99/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6479 - accuracy: 0.8731\n",
      "Epoch 100/100\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 0.6308 - accuracy: 0.8743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3ef9fa3d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,LSTM\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_dim = 128\n",
    "num_epoch = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_dim))\n",
    "model.add(LSTM(hidden_dim,return_sequences = False)) # 원래 False가 default지만 다 대 일 구조를 강조하고자 입력함.\n",
    "model.add(Dense(vocab_size,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=num_epoch,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14929f",
   "metadata": {},
   "source": [
    "#### 문장을 생성하는 함수 sentence_generation을 만들어서 다음 시점의 단어를 예측하고 문장을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b6b3643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i disapprove of school vouchers can i still apply for them\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    \n",
    "    # current_word를 계속 쌓아 나가서 다음 단어를 예측하는 것을 재귀적으로 n번 반복하는 느낌.\n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') # max_len-1은 X,y로 분리되었기 때문에 -1을 한 것.\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0) # shape : (1,vocab_size)\n",
    "        result = np.argmax(result, axis=1) # 가장 확률이 높은 index를 추출.\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # current_word를 {' ' + 예측 단어}를 추가해서 저장하고 다음 입력으로 사용\n",
    "        current_word = current_word + ' '  + word\n",
    "\n",
    "        # 예측 단어를 문장에 저장해서 최종 출력에 사용하기.\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "print(sentence_generation(model, tokenizer, 'i', 10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bcd34",
   "metadata": {},
   "source": [
    "근데 i 하나만 주어지고 나머지를 예측하는게 좀 웃기긴 하다. i 다음으로 나올 수 있는게 얼마나 많은데.. 그냥 지금은 이런 느낌으로 학습을 진행하고 예측한다고만 생각하자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
