{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7ad818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 자동 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d927a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w= tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "    y = w**2\n",
    "    z = 2*y + 5\n",
    "    return z\n",
    "\n",
    "with tf.GradientTape() as tape :\n",
    "    z=f(w)\n",
    "    \n",
    "gradients = tape.gradient(z,[w]) # z를 w로 미분하고 w를 대입해준 듯.\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cd73361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 자동 미분을 이용한 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc7a5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 21. 23. 25.]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "# @tf.fucnction annotation을 붙이면 마치 tf2.x 버전에서도 tf1.x 형태처럼 \n",
    "# 그래프 생성과 실행이 분리된 형태로 해당 함수내의 로직이 실행되게 됩니다. 참고 : https://www.inflearn.com/questions/174459\n",
    "\n",
    "@tf.function\n",
    "def hypothesis(x):\n",
    "    return w*x+b\n",
    "\n",
    "x_test = [3.5,5,5.5,6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43c15e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차 함수 정의\n",
    "@tf.function\n",
    "def mse_loss(y_pred,y):\n",
    "    return tf.reduce_mean(tf.square(y_pred-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa93e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22fdcfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1846cbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w의 미분 값 : -421.33337 b의 미분 값 : -66.44445\n",
      "epoch :   0 | w의 값 : 8.2133 | b의 값 : 1.664 | cost : 1402.555542\n",
      "w의 미분 값 : -0.08866286 b의 미분 값 : 0.48123774\n",
      "epoch :  10 | w의 값 : 10.4971 | b의 값 : 1.977 | cost : 1.351182\n",
      "w의 미분 값 : -0.073672056 b의 미분 값 : 0.46364763\n",
      "epoch :  20 | w의 값 : 10.5047 | b의 값 :  1.93 | cost : 1.328163\n",
      "w의 미분 값 : -0.0707078 b의 미분 값 : 0.44495025\n",
      "epoch :  30 | w의 값 : 10.5119 | b의 값 : 1.884 | cost : 1.306966\n",
      "w의 미분 값 : -0.06786013 b의 미분 값 : 0.4270077\n",
      "epoch :  40 | w의 값 : 10.5188 | b의 값 : 1.841 | cost : 1.287436\n",
      "w의 미분 값 : -0.06512523 b의 미분 값 : 0.40978903\n",
      "epoch :  50 | w의 값 : 10.5254 | b의 값 : 1.799 | cost : 1.269459\n",
      "w의 미분 값 : -0.06250572 b의 미분 값 : 0.3932637\n",
      "epoch :  60 | w의 값 : 10.5318 | b의 값 : 1.759 | cost : 1.252897\n",
      "w의 미분 값 : -0.06002426 b의 미분 값 : 0.37739924\n",
      "epoch :  70 | w의 값 : 10.5379 | b의 값 : 1.721 | cost : 1.237644\n",
      "w의 미분 값 : -0.05755186 b의 미분 값 : 0.362189\n",
      "epoch :  80 | w의 값 : 10.5438 | b의 값 : 1.684 | cost : 1.223597\n",
      "w의 미분 값 : -0.055271626 b의 미분 값 : 0.3475793\n",
      "epoch :  90 | w의 값 : 10.5494 | b의 값 : 1.648 | cost : 1.210658\n",
      "w의 미분 값 : -0.053044796 b의 미분 값 : 0.33356202\n",
      "epoch : 100 | w의 값 : 10.5548 | b의 값 : 1.614 | cost : 1.198740\n",
      "w의 미분 값 : -0.050844908 b의 미분 값 : 0.3201212\n",
      "epoch : 110 | w의 값 : 10.5600 | b의 값 : 1.582 | cost : 1.187767\n",
      "w의 미분 값 : -0.048835754 b의 미분 값 : 0.30720758\n",
      "epoch : 120 | w의 값 : 10.5650 | b의 값 :  1.55 | cost : 1.177665\n",
      "w의 미분 값 : -0.046858788 b의 미분 값 : 0.2948208\n",
      "epoch : 130 | w의 값 : 10.5697 | b의 값 :  1.52 | cost : 1.168354\n",
      "w의 미분 값 : -0.044947863 b의 미분 값 : 0.2829359\n",
      "epoch : 140 | w의 값 : 10.5743 | b의 값 : 1.492 | cost : 1.159782\n",
      "w의 미분 값 : -0.043134928 b의 미분 값 : 0.27152696\n",
      "epoch : 150 | w의 값 : 10.5787 | b의 값 : 1.464 | cost : 1.151890\n",
      "w의 미분 값 : -0.041410923 b의 미분 값 : 0.26057604\n",
      "epoch : 160 | w의 값 : 10.5829 | b의 값 : 1.437 | cost : 1.144619\n",
      "w의 미분 값 : -0.0397439 b의 미분 값 : 0.25006825\n",
      "epoch : 170 | w의 값 : 10.5870 | b의 값 : 1.412 | cost : 1.137924\n",
      "w의 미분 값 : -0.038116455 b의 미분 값 : 0.23998728\n",
      "epoch : 180 | w의 값 : 10.5909 | b의 값 : 1.387 | cost : 1.131752\n",
      "w의 미분 값 : -0.03657818 b의 미분 값 : 0.2303102\n",
      "epoch : 190 | w의 값 : 10.5946 | b의 값 : 1.364 | cost : 1.126073\n",
      "w의 미분 값 : -0.035115242 b의 미분 값 : 0.22102192\n",
      "epoch : 200 | w의 값 : 10.5982 | b의 값 : 1.341 | cost : 1.120843\n",
      "w의 미분 값 : -0.03369093 b의 미분 값 : 0.21211073\n",
      "epoch : 210 | w의 값 : 10.6016 | b의 값 :  1.32 | cost : 1.116026\n",
      "w의 미분 값 : -0.032380104 b의 미분 값 : 0.20354947\n",
      "epoch : 220 | w의 값 : 10.6049 | b의 값 : 1.299 | cost : 1.111589\n",
      "w의 미분 값 : -0.031059027 b의 미분 값 : 0.19534558\n",
      "epoch : 230 | w의 값 : 10.6081 | b의 값 : 1.279 | cost : 1.107504\n",
      "w의 미분 값 : -0.029765606 b의 미분 값 : 0.18747455\n",
      "epoch : 240 | w의 값 : 10.6111 | b의 값 :  1.26 | cost : 1.103736\n",
      "w의 미분 값 : -0.028553009 b의 미분 값 : 0.17991571\n",
      "epoch : 250 | w의 값 : 10.6140 | b의 값 : 1.242 | cost : 1.100273\n",
      "w의 미분 값 : -0.027417183 b의 미분 값 : 0.17265874\n",
      "epoch : 260 | w의 값 : 10.6168 | b의 값 : 1.224 | cost : 1.097082\n",
      "w의 미분 값 : -0.026365042 b의 미분 값 : 0.16568819\n",
      "epoch : 270 | w의 값 : 10.6195 | b의 값 : 1.207 | cost : 1.094143\n",
      "w의 미분 값 : -0.025274515 b의 미분 값 : 0.1590118\n",
      "epoch : 280 | w의 값 : 10.6221 | b의 값 : 1.191 | cost : 1.091434\n",
      "w의 미분 값 : -0.024228096 b의 미분 값 : 0.15260342\n",
      "epoch : 290 | w의 값 : 10.6245 | b의 값 : 1.176 | cost : 1.088940\n",
      "w의 미분 값 : -0.023300648 b의 미분 값 : 0.14644244\n",
      "epoch : 300 | w의 값 : 10.6269 | b의 값 : 1.161 | cost : 1.086645\n"
     ]
    }
   ],
   "source": [
    "for i in range(301):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
    "        y_pred = hypothesis(x)\n",
    "\n",
    "        # 평균 제곱 오차를 계산\n",
    "        cost = mse_loss(y_pred, y)\n",
    "\n",
    "    # 손실 함수에 대한 파라미터 w,b의 미분값 계산\n",
    "    gradients = tape.gradient(cost, [w, b])\n",
    "    # 파라미터 업데이트\n",
    "    optimizer.apply_gradients(zip(gradients, [w, b]))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"w의 미분 값 :\",gradients[0].numpy(), \"b의 미분 값 :\",gradients[1].numpy())\n",
    "        print(\"epoch : {:3} | w의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, w.numpy(), b.numpy(), cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0a72624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.35479  54.295143 59.608593 64.92204 ]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ec6f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 케라스로 구현하는 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59ad86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 4331.0371 - mse: 4331.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 534.0167 - mse: 534.0167\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 66.8202 - mse: 66.8202\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3337 - mse: 9.3337\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2589 - mse: 2.2589\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3869 - mse: 1.3869\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2782 - mse: 1.2782\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2633 - mse: 1.2633\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2601 - mse: 1.2601\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2582 - mse: 1.2582\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2566 - mse: 1.2566\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2550 - mse: 1.2550\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2534 - mse: 1.2534\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2518 - mse: 1.2518\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2502 - mse: 1.2502\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2486 - mse: 1.2486\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2471 - mse: 1.2471\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2456 - mse: 1.2456\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2440 - mse: 1.2440\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2425 - mse: 1.2425\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2410 - mse: 1.2410\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2395 - mse: 1.2395\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2381 - mse: 1.2381\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2366 - mse: 1.2366\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2352 - mse: 1.2352\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2337 - mse: 1.2337\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2323 - mse: 1.2323\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2309 - mse: 1.2309\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2295 - mse: 1.2295\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2281 - mse: 1.2281\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2267 - mse: 1.2267\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2254 - mse: 1.2254\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2240 - mse: 1.2240\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2226 - mse: 1.2226\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2213 - mse: 1.2213\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2200 - mse: 1.2200\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2187 - mse: 1.2187\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2174 - mse: 1.2174\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2161 - mse: 1.2161\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2148 - mse: 1.2148\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2135 - mse: 1.2135\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2123 - mse: 1.2123\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2110 - mse: 1.2110\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2098 - mse: 1.2098\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2086 - mse: 1.2086\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2073 - mse: 1.2073\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2061 - mse: 1.2061\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2049 - mse: 1.2049\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2037 - mse: 1.2037\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2026 - mse: 1.2026\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2014 - mse: 1.2014\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2002 - mse: 1.2002\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1991 - mse: 1.1991\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1979 - mse: 1.1979\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1968 - mse: 1.1968\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1957 - mse: 1.1957\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1946 - mse: 1.1946\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1935 - mse: 1.1935\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1924 - mse: 1.1924\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1913 - mse: 1.1913\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1902 - mse: 1.1902\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1891 - mse: 1.1891\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1881 - mse: 1.1881\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1870 - mse: 1.1870\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1860 - mse: 1.1860\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1850 - mse: 1.1850\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1839 - mse: 1.1839\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1829 - mse: 1.1829\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1819 - mse: 1.1819\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1809 - mse: 1.1809\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1799 - mse: 1.1799\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1789 - mse: 1.1789\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1780 - mse: 1.1780\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1770 - mse: 1.1770\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1760 - mse: 1.1760\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1751 - mse: 1.1751\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1741 - mse: 1.1741\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1732 - mse: 1.1732\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1723 - mse: 1.1723\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1713 - mse: 1.1713\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1704 - mse: 1.1704\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1695 - mse: 1.1695\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1686 - mse: 1.1686\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1677 - mse: 1.1677\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1668 - mse: 1.1668\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1660 - mse: 1.1660\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1651 - mse: 1.1651\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1642 - mse: 1.1642\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1634 - mse: 1.1634\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1625 - mse: 1.1625\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1617 - mse: 1.1617\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1609 - mse: 1.1609\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1600 - mse: 1.1600\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1592 - mse: 1.1592\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1584 - mse: 1.1584\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1576 - mse: 1.1576\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1568 - mse: 1.1568\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1560 - mse: 1.1560\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1552 - mse: 1.1552\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1544 - mse: 1.1544\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1536 - mse: 1.1536\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1529 - mse: 1.1529\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1521 - mse: 1.1521\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1514 - mse: 1.1514\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1506 - mse: 1.1506\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1499 - mse: 1.1499\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1491 - mse: 1.1491\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1484 - mse: 1.1484\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1477 - mse: 1.1477\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1469 - mse: 1.1469\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1462 - mse: 1.1462\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1455 - mse: 1.1455\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1448 - mse: 1.1448\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1441 - mse: 1.1441\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1434 - mse: 1.1434\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1428 - mse: 1.1428\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1421 - mse: 1.1421\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1414 - mse: 1.1414\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1407 - mse: 1.1407\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1401 - mse: 1.1401\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1394 - mse: 1.1394\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1388 - mse: 1.1388\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1381 - mse: 1.1381\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1375 - mse: 1.1375\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1368 - mse: 1.1368\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1362 - mse: 1.1362\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1356 - mse: 1.1356\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1350 - mse: 1.1350\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1343 - mse: 1.1343\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1337 - mse: 1.1337\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1331 - mse: 1.1331\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1325 - mse: 1.1325\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1319 - mse: 1.1319\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1313 - mse: 1.1313\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1308 - mse: 1.1308\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1302 - mse: 1.1302\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1296 - mse: 1.1296\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1290 - mse: 1.1290\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1285 - mse: 1.1285\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1279 - mse: 1.1279\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1273 - mse: 1.1273\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1268 - mse: 1.1268\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1262 - mse: 1.1262\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1257 - mse: 1.1257\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1252 - mse: 1.1252\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1246 - mse: 1.1246\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1241 - mse: 1.1241\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1236 - mse: 1.1236\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1230 - mse: 1.1230\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1225 - mse: 1.1225\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1220 - mse: 1.1220\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1215 - mse: 1.1215\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1210 - mse: 1.1210\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1205 - mse: 1.1205\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1200 - mse: 1.1200\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1195 - mse: 1.1195\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1190 - mse: 1.1190\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1185 - mse: 1.1185\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1180 - mse: 1.1180\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1176 - mse: 1.1176\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1171 - mse: 1.1171\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1166 - mse: 1.1166\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1162 - mse: 1.1162\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1157 - mse: 1.1157\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1152 - mse: 1.1152\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1148 - mse: 1.1148\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1143 - mse: 1.1143\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1139 - mse: 1.1139\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1135 - mse: 1.1135\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1130 - mse: 1.1130\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1126 - mse: 1.1126\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1121 - mse: 1.1121\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1117 - mse: 1.1117\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1113 - mse: 1.1113\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1109 - mse: 1.1109\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1105 - mse: 1.1105\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1100 - mse: 1.1100\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1096 - mse: 1.1096\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1092 - mse: 1.1092\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1088 - mse: 1.1088\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1084 - mse: 1.1084\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1080 - mse: 1.1080\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1076 - mse: 1.1076\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1072 - mse: 1.1072\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1068 - mse: 1.1068\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1065 - mse: 1.1065\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1061 - mse: 1.1061\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1057 - mse: 1.1057\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1053 - mse: 1.1053\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1049 - mse: 1.1049\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1046 - mse: 1.1046\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1042 - mse: 1.1042\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1038 - mse: 1.1038\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1035 - mse: 1.1035\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1031 - mse: 1.1031\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1028 - mse: 1.1028\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1024 - mse: 1.1024\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1021 - mse: 1.1021\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1017 - mse: 1.1017\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1014 - mse: 1.1014\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1010 - mse: 1.1010\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1007 - mse: 1.1007\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1004 - mse: 1.1004\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1000 - mse: 1.1000\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0997 - mse: 1.0997\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0994 - mse: 1.0994\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0991 - mse: 1.0991\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0987 - mse: 1.0987\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0984 - mse: 1.0984\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0981 - mse: 1.0981\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0978 - mse: 1.0978\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0975 - mse: 1.0975\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0972 - mse: 1.0972\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0969 - mse: 1.0969\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0966 - mse: 1.0966\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0963 - mse: 1.0963\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0960 - mse: 1.0960\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0957 - mse: 1.0957\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0954 - mse: 1.0954\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0951 - mse: 1.0951\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0948 - mse: 1.0948\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0945 - mse: 1.0945\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0942 - mse: 1.0942\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0939 - mse: 1.0939\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0937 - mse: 1.0937\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0934 - mse: 1.0934\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0931 - mse: 1.0931\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0928 - mse: 1.0928\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0926 - mse: 1.0926\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0923 - mse: 1.0923\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0920 - mse: 1.0920\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0918 - mse: 1.0918\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0915 - mse: 1.0915\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0913 - mse: 1.0913\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0910 - mse: 1.0910\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0907 - mse: 1.0907\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0905 - mse: 1.0905\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0902 - mse: 1.0902\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0900 - mse: 1.0900\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0897 - mse: 1.0897\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0895 - mse: 1.0895\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0893 - mse: 1.0893\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0890 - mse: 1.0890\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0888 - mse: 1.0888\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0883 - mse: 1.0883\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0881 - mse: 1.0881\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0874 - mse: 1.0874\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0872 - mse: 1.0872\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0869 - mse: 1.0869\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0867 - mse: 1.0867\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0865 - mse: 1.0865\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0863 - mse: 1.0863\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0861 - mse: 1.0861\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0858 - mse: 1.0858\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0854 - mse: 1.0854\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0850 - mse: 1.0850\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0848 - mse: 1.0848\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0846 - mse: 1.0846\n",
      "Epoch 264/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0844 - mse: 1.0844\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0842 - mse: 1.0842\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0840 - mse: 1.0840\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0838 - mse: 1.0838\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0836 - mse: 1.0836\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0834 - mse: 1.0834\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0832 - mse: 1.0832\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0830 - mse: 1.0830\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0828 - mse: 1.0828\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0826 - mse: 1.0826\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0824 - mse: 1.0824\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0823 - mse: 1.0823\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0821 - mse: 1.0821\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0819 - mse: 1.0819\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0817 - mse: 1.0817\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0815 - mse: 1.0815\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0814 - mse: 1.0814\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0812 - mse: 1.0812\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0810 - mse: 1.0810\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0808 - mse: 1.0808\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0807 - mse: 1.0807\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0805 - mse: 1.0805\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0803 - mse: 1.0803\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0802 - mse: 1.0802\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0800 - mse: 1.0800\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0798 - mse: 1.0798\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0797 - mse: 1.0797\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0795 - mse: 1.0795\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0793 - mse: 1.0793\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0792 - mse: 1.0792\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0790 - mse: 1.0790\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0789 - mse: 1.0789\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0787 - mse: 1.0787\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0786 - mse: 1.0786\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0784 - mse: 1.0784\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0782 - mse: 1.0782\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0781 - mse: 1.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29cb595f40>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential()로 기반을 만들고 add를 통해 layer를 추가하는 방식. -> 파이토치에서도 자주 보는 방식이다.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=1,activation = \"linear\")) # activation도 하나로 세트로 묶여있는 듯.\n",
    "\n",
    "# 옵티마이저 생성\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 손실 함수 생성\n",
    "model.compile(optimizer=sgd,loss='mse',metrics=['mse'])\n",
    "\n",
    "# 학습 시작\n",
    "model.fit(x,y,epochs=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "332297e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f29cb4513d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f29cb451400>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfCElEQVR4nO3deZSU1bXG4d+moRxIFBVUBBWNNyqiIqJQqKSgMU654k1i1JsYjASMQaIxCWi8zgkoOOHEHMUZBGQwgENJSdASbQaZVcSgIEOjoKJCQfe5f5xCCTJ1VzWnhvdZi9Vd1dVdb1xks3t/5zvHnHOIiEhhqRU6gIiIZJ+Ku4hIAVJxFxEpQCruIiIFSMVdRKQAqbiLiBSgnRZ3M/uHma0ys7lbPLe/mb1kZu+lP+6Xft7M7H4zW2Rms82sRU2GFxGRbbOdrXM3s7bAOuAx51yz9HN9gE+dc3eY2XXAfs65nmZ2LtAdOBdoBfRzzrXaWYj69eu7Jk2aZPa/RESkyEyfPn21c67Btr5We2ff7JybYmZNtnq6IxBLfz4MSAA9088/5vy/GG+YWT0za+icW76j92jSpAllZWU7iyIiIlswsyXb+1p1Z+4HbVGwVwAHpT9vBHy0xeuWpp8TEZHdKOMLqukuvcp7GJhZVzMrM7Oy8vLyTGOIiMgWqlvcV5pZQ4D0x1Xp55cBh27xusbp577DOTfIOdfSOdeyQYNtjoxERKSaqlvcxwGd0p93AsZu8fyv06tmWgOf7WzeLiIi2bfTC6pm9jT+4ml9M1sK3AzcAYwws87AEuAX6ZdPwK+UWQR8BfymBjKLiMhO7MpqmUu286XSbbzWAd0yDSUiIpnRHaoiIgVIxV1EJIAvv4SePWHJdleqZ0bFXURkN3v5ZTj+eOjTByZMqJn3UHEXEdlNPv0ULr8czjwTateGRAKuvLJm3kvFXUSkhjkHzz4LTZvCY4/B9dfD229DJJKkd+/eJJPJrL/nTlfLiIhI9S1bBt26wdix0KIFTJoEzZtDMpmktLSUVCpFJBIhHo8TjUaz9r7q3EVEakBlJQwa5Lv1F17w8/Vp03xhB0gkEqRSKSoqKkilUiQSiay+vzp3EZEse/dd6NoVXn0V2rXzRf6oo/7zNbFYjEgk8k3nHovFsppBxV1EJEs2boS774ZbboE994QhQ/wFVLPvvjYajRKPx0kkEsRisayOZEDFXUQkK2bMgM6dYdYs+OlP4cEHoWHDHX9PNBrNelHfTDN3EZEMfPUV9OgBp54KK1bAqFH+z84Ke01T5y4iUk2TJ0OXLvD++/Db30LfvlCvXuhUnjp3EZEqWrvWF/X27f3jeBwGD86dwg4q7iIiVfLcc3554yOP+HHM7NnfFvlcorGMiMguWLECrrrKz9ObN4fnn/c3JeUqde4iIjvgHAwdCsce6wt6797w5pu5XdhBnbuIyHa9/76/GemVV6BtWz9X/+EPQ6faNercRUS2smkT3HWX35a3rAwGDvQrY/KlsIM6dxGR/zBrll/WOH06dOwIDz0EjRqFTlV16txFRID16+Gvf4WWLeGjj2DECL8yJh8LO6hzFxFhyhS/bv3dd+Gyy/z+MPvvHzpVZtS5i0jR+uwzfxLSj37kN/166SW/fj3fCzuouItIkRo3Do47zm/He+21MGcOdOgQOlX2aCwjIgUvmUx+s7XukUdG+cMf/Ez9+ONh9Gi/6VehUXEXkYK25XF2JSUR9tgjzoYNUf72N/jLXyASCZ2wZqi4i0hBSyQSbNiQorKygoqKFA0bJpg0Kcoxx4ROVrM0cxeRglVRAStXxqisjAAl1KkT4cknYwVf2EGdu4gUqDlz/M1Ib74ZpU2bOKefnuCCC7J/nF2uUnEXkYKyYQP8/e9+g6/99oOnn4aLLopiVhxFfTMVdxEpGK+/7rv1BQvg0kvhnnugfv3QqcLQzF1E8t4XX0D37nD66fDllzBxIjz2WPEWdlBxF5E8N2GCvxnpoYd8gZ83D84+O3Sq8DSWEZG8VF4O11wDTz3lj7177TUokmulu0Sdu4jkFefgySf9yUjPPgu33AIzZqiwb02du4jkjSVL/EZfEydC69YwZIgfych3qXMXkZxXUQEPPOAL+ZQp0K8fTJ2qwr4j6txFJKfNn++XNyaT/kLpgAFw+OGhU+W+jDp3M/ujmc0zs7lm9rSZ7WlmR5jZNDNbZGbDzaxAt+URkZqUSsFtt8FJJ/lDNB5/3K+MUWHfNdUu7mbWCPgD0NI51wwoAS4G7gTudc4dBawBOmcjqIgUj2nToEULuPlm+NnPfPf+q1+BWehk+SPTmXttYC8zqw3sDSwH2gMj018fBlyQ4XuISJFYt84vb4xG/SlJzz/vlzoeeGDoZPmn2sXdObcMuAv4EF/UPwOmA2udc5vSL1sK5OnxsiKyO734IjRr5i+W/v73/mak884LnSp/ZTKW2Q/oCBwBHALUBXb5vjAz62pmZWZWVl5eXt0YIpLnPvkEOnWCs86Cvfbyq2AefBD22Sd0svyWyVimA/CBc67cObcRGA2cBtRLj2kAGgPLtvXNzrlBzrmWzrmWDRo0yCCGiOQj52D4cH8z0lNPwf/9H8ycCaedFjpZYcikuH8ItDazvc3MgFJgPjAZ+Hn6NZ2AsZlFFJFCs3QpdOwIF18MTZrA9Olw++2w556hkxWOTGbu0/AXTmcAc9I/axDQE7jWzBYBBwBDs5BTRApAZSX07+/3gnn5Zb8lbzIJJ5wQOlnhyegmJufczcDNWz29GCjAs8RFJBPvvANdusC//gUdOsDAgXDkkaFTFS5tPyAiWZNMJunduzfJZPKb5zZuhF694MQTYe5ceOQRvzJGhb1mafsBEcmKZDJJaWkpqVSKSCRCPB6nTp0onTvD7Nlw4YVw//1w8MGhkxYHde4ikhWJRIJUKkVFRQWpVIoePRK0agWrV8OYMTBihAr77qTiLiJZEYvFiEQi1KpVQmVlhKlTY3Tp4rcO6NgxdLrio+IuIllxzDFRSkvjVFbeTqNGcRKJKAMGwL77hk5WnDRzF5GMjRoF3brB6tVRrrsuyk03+btNJRwVdxGpto8/hquuguee87s4Tpzot+iV8DSWEZEqq6yEwYP9zUgTJ0KfPn6bXhX23KHOXUSqZNEifzNSIgHt2sGgQXDUUaFTydbUuYvILtm0Ce68E44/3m/wNXgwxOMq7LlKnbuI7NTMmdC5s//405/6LXkbNgydSnZEnbuIbNfXX8N118Epp8Dy5X5VzKhRKuz5QJ27iGxTIuFn64sW+a69b1/Yb7/QqWRXqXMXkf+wdi107eovllZW+rn6kCEq7PlGxV1EvjFmjF/eOHQo/PnPMGcOtG8fOpVUh8YyIsKKFdC9O4wc6bfmHT8eTj45dCrJhDp3kSLmHPzjH/4c0/Hj/b7rb72lwl4I1LmLFKnFi/1sPR6HM87w69aPPjp0KskWde4iRWbTJrj7bmjWDN58059pmkiosBcade4iRWT2bL+ssawM/vu/4eGHoXHj0KmkJqhzFykC69fDDTf4WfqHH8Lw4TB2rAp7IVPnLlLg/vUvfzPSO+9Ap05+JHPAAaFTSU1T5y5SoD7/HH7/e2jbFjZsgBdegEcfVWEvFiruIgXo+efhuONgwAD44x9h7lz48Y9Dp5LdScVdpICsWgWXXOIvltarB8kk3HMP1K0bOpnsbiruInkomUzSu3dvkskk4G9GeuwxfzPS6NFw220wfTq0ahU4qASjC6oieSaZTFJaWkoqlSISifDEE3EGDozy4ovQps23x99JcVNxF8kziUSCVCpFRUUFGzakuPjiBHvsEeWBB/wF1Fr6fVxQcRfJO7FYjDp1IlRUpKisjHDqqTGGD4fDDgudTHKJirtIHtmwASZNirJxY5y9907Qo0eMm26KYhY6meQaFXeRPPH66/Db38KCBfDLX0a5774o9euHTiW5StM5kRz3xRd+r/XTT4d162DCBHjiCVTYZYdU3EVy2MSJfvfGhx6Cq66CefPgnHNCp5J8oOIukoNWr4Zf/QrOPdffgDR1Ktx/P3z/+6GTSb5QcRfJIc7BU0/5m5FGjICbboKZM/36dZGq0AVVkRzx4Ydw5ZV+pt6qFQwZ4kcyItWhzl0ksMpKePBBv9FXIgH33QevvabCLpnJqLibWT0zG2lmC81sgZlFzWx/M3vJzN5Lf9wvW2FFCs2CBf780u7d/ehl3jy4+mooKQmdTPJdpp17P2CSc+4Y4ERgAXAdEHfO/RcQTz8WkS2kUnD77dC8OSxcCMOGwaRJ0KRJ6GRSKKo9czezfYG2wGUAzrkUkDKzjkAs/bJhQALomUlIkUIybZq/GWnuXLjoIr8K5sADQ6eSQpNJ534EUA48YmYzzWyImdUFDnLOLU+/ZgVwUKYhRQrBl1/6gzOiUVizBsaNg2eeUWGXmpFJca8NtAD6O+dOAr5kqxGMc84BblvfbGZdzazMzMrKy8sziCGS+1580V8gve8++N3vYP58f6CGSE3JpLgvBZY656alH4/EF/uVZtYQIP1x1ba+2Tk3yDnX0jnXskGDBhnEEMldn3wCl10GZ50FkQhMmQIPPwz77BM6mRS6ahd359wK4CMzOzr9VCkwHxgHdEo/1wkYm1FCkTzkHAwf7g/NePJJuOEGePttvzJGZHfI9Cam7sCTZhYBFgO/wf+DMcLMOgNLgF9k+B4ieWXpUn9oxvjx0LKlH8mceGLoVFJsMiruzrlZQMttfKk0k58rko8qK2HQIOjRAzZtgrvu8mvWa+s+cAlAf+1EsuCdd6BrVz9Tb9/eF/kf/CB0Kilm2n5AJAMbN0KvXn7sMns2DB0KL7+swi7hqXMXqaayMn8z0ttvw89/Dg88AAcfHDqViKfOXaSKvvoK/vIXv3PjqlUwejQ8+6wKu+QWde4iVfDKK9ClCyxe7D/26QP16oVOJfJd6txFdsGaNX4EU1oKtWrB5Mn+oqkKu+QqFXeRnRg1yt+M9Oij0LOnv3Aai4VOJbJjGsuIbMfHH/tDqZ97Dk46Cf75T2jRInQqkV2jzl1kK875I+6aNoWJE+GOO/w2vSrskk/UuYtsYdEifzPS5MnQvHmS9u0TtG0bo06daOhoIlWizl0Ev11Anz5w/PEwfTr07JnknXdK6dfvRkpLS0kmk6EjilSJirsUvVmz/Jr1nj3h7LP9uab77psglUpRUVFBKpUikUiEjilSJSruUrS+/hquv97v3Lhsmb8RafRoOOQQiMViRCIRSkpKiEQixLQ8RvKMZu5SlF591d+E9N57cPnl0Lcv7L//t1+PRqPE43ESiQSxWIxoVDN3yS8q7lJUPvvMb8k7aBAceaTf5Kt0OxtUR6NRFXXJWxrLSNEYO9YvbxwyBP70J5gzZ/uFXSTfqbhLwVu5En7xC7jgAqhfH954wx+ksffeoZOJ1BwVdylYzvktA4491nftf/+736b3lFNCJxOpeZq5S0FavBiuuMLP1E8/HQYPhmOOCZ1KZPdR5y4FpaIC7rnH34w0bRo8/LBfGaPCLsVGnbsUjNmz/ba8b70FP/kJ9O8PjRuHTiUShjp3yXvr18ONN8LJJ8O//w3PPAPjxqmwS3FT5y55bepUfzPSwoXw61/7kcwBB4ROJRKeOnfJS59/Dt26wRln+G0EJk2CYcNU2EU2U3GXvPPPf8Jxx/mZ+jXXwNy5cNZZoVOJ5BYVd8kb5eXwv//rL5buuy8kk3DvvfC974VOJpJ7VNwl5zkHjz/ub0YaORJuvRVmzPDb9IrItumCquS0JUvgd7/zM/Vo9Nvj70Rkx9S5S06qqID77/ez9alT4YEH/EcVdpFdo85dcs68ef5mpDfegHPOgQED4LDDQqcSyS8q7hJcMpkkkUjQpk2MyZOj9OoF++wDTzzhL6CahU4okn9U3CWoZDJJaWkpGzakcC6Cc3F++cso994LDRqETieSvzRzl6BeeCHB+vUpKisrcC5Fp04JnnhChV0kUyruEswLL8DAgTGci2BWwl57RbjiiljoWCIFQWMZ2e1Wr4Zrr928dj3KrbfG+eQTHUQtkk0q7rLbOOd3bLz6alizxu/keMMNsMceUUBFXSSbVNxlt/joI7jySr8vzKmnQjzuD9QQkZqR8czdzErMbKaZPZ9+fISZTTOzRWY23MwimceUfFVZ6U9DOu44mDzZ7wXz+usq7CI1LRsXVK8GFmzx+E7gXufcUcAaoHMW3kPy0MKF0Lat35q3dWu/e+M110BJSehkIoUvo+JuZo2B84Ah6ccGtAdGpl8yDLggk/eQ/JNKwd/+BieeCPPnw6OP+pUxRxwROplI8ch05n4f0AP4fvrxAcBa59ym9OOlQKMM30PyyFtvQefOMGcOXHQR9OsHBx0UOpVI8al2525mPwFWOeemV/P7u5pZmZmVlZeXVzeG5Igvv/TLG1u3hk8/hbFj/coYFXaRMDLp3E8Dzjezc4E9gX2AfkA9M6ud7t4bA8u29c3OuUHAIICWLVu6DHJIYC+/DF27wgcf+O1577jDH6YhIuFUu3N3zl3vnGvsnGsCXAy84pz7JTAZ+Hn6ZZ2AsRmnlJz06afwm9/AmWdCnTrw6qv+6DsVdpHwamL7gZ7AtWa2CD+DH1oD7yEBOQfPPuv3Vn/8cfjrX+Htt/3KGBHJDVm5ick5lwAS6c8XA6dm4+dK7lm2zC9tHDsWTj7Zr4I58cTQqURka9o4THZJZSUMHOi79RdfhL59/WEaKuwiuUnbD8hOvfuuv2D66qvQvj0MGgQ/+EHoVCKyI+rcZbs2bvQrX044AWbN8odTv/yyCrtIPlDnLts0fbo/x3TWLPjZz/wB1Q0bhk4lIrtKnbv8h6++gh49oFUrWLkSRo+GkSNV2EXyjTp3+cbkydClC7z/vu/a+/aFevVCpxKR6lDnLqxd64t6+/b+8SuvwODBKuwi+UzFvciNHg3HHguPPOLHMXPmQLt2oVOJSKY0lilSy5fDVVf54t68uT8hqUWL0KlEJFtU3ItIMplk8uQE69bF6N8/ytdfQ+/e8Kc/+b1hRKRwqLgXiWQySfv2paxfnwIiNG8eZ/jwKD/8YehkIlITNHMvAps2wW23JdKFvYJatVJceGFChV2kgKm4F7hZs/wBGpMmxahVK0JJSQl77BGhXbtY2GAiUqM0lilQ69fDbbdBnz5wwAEwYkSURo3ivPpqglgsRjQaDR1RRGqQinsBmjLFr1t/91247DK4+27Yf3+AKG3aqKiLFAONZQrIZ5/5Y+5+9CO/6ddLL/n1676wi0gxUXEvEOPGwXHH+TtLr73W34zUoUPoVCISiop7nlu5Ei66CDp29B16MunHMHXrhk4mIiGpuOcp52DYML91wJgxcPvtUFYGp+qAQxFBF1Tz0gcfwBVX+Jn6aaf5Ucyxx4ZOJSK5RJ17HqmogHvvhWbN/PjloYf8yhgVdhHZmjr3PDFnjt9j/c034bzzoH9/OPTQ0KlEJFepc89xGzbAjTf6HRsXL4annoLx41XYRWTH1LnnsNde8936woVw6aVwzz1Qv37oVCKSD9S556AvvvB7rZ9xhj/TdOJEeOwxFXYR2XUq7jlmwgR/M9LDD0P37jBvHpx9duhUIpJvNJbJEeXlcM01fqbetKkfyWhvLxGpLnXugTkHTzzhlzM++yzccgvMmKHCLiKZUece0JIlcOWVfqbeujUMGeJHMiIimVLnHkBFBTzwgC/kU6ZAv34wdaoKu4hkjzr33Wz+fL+8MZmEs86CgQPh8MNDpxKRQqPOfTdJpeDWW6F5c3+IxuOP+3GMCruI1AR17rvBG2/4bn3ePLjkErjvPjjwwNCpRKSQqXOvQevW+eWNbdr4U5LGj/dLHVXYRaSmqXOvIS+84LflXbIEunWDXr1gn31CpxKRYqHinmWffAKXXppk4sQEhx8eY+rUKKedFjqViBQbFfcscQ6GD4crr0yydm0pZilWrYpQq1Yc0B1JIrJ7VXvmbmaHmtlkM5tvZvPM7Or08/ub2Utm9l76437Zi5ubli6F88/3F0vr1k1Qq1YK5ypIpVIkEonQ8USkCGVyQXUT8CfnXFOgNdDNzJoC1wFx59x/AfH044JUWekPzWjaFOJxfzD1M8/E2GOPCCUlJUQiEWKxWOiYIlKEqj2Wcc4tB5anP//CzBYAjYCOQCz9smFAAuiZUcoctHAhdOni7yzt0MHfjHTkkQBR4vE4iUSCWCxGVJvEiEgAWZm5m1kT4CRgGnBQuvADrAAOysZ75IqNG6FPH7jtNqhbFx55BDp1ArNvXxONRlXURSSojIu7mX0PGAVc45z73Laocs45Z2ZuO9/XFegKcNhhh2UaY7coK4POnWH2bLjwQrj/fjj44NCpRES+K6ObmMysDr6wP+mcG51+eqWZNUx/vSGwalvf65wb5Jxr6Zxr2aBBg0xi1LivvoI//xlatYLVq2HMGBgxQoVdRHJXJqtlDBgKLHDO3bPFl8YBndKfdwLGVj9eePE4HH+8v1japYvf+Ktjx9CpRER2LJPO/TTgUqC9mc1K/zkXuAM408zeAzqkH+edNWvg8sv9xdKSEkgkYMAA2Hff0MlERHYuk9UyUwHbzpdLq/tzQ3MORo3yB1SvXg3XXQc33QR77RU6mYjIrtMdqlv4+GO/D8yYMdCihd+S96STQqcSEak67QqJvxlp0CB/jumkSX6p47RpKuwikr+KvnN/7z3o2tXP1Nu180X+qKNCpxIRyUzRdu6bNsGdd8IJJ8DMmTB4sF8Zo8IuIoWgKDv3mTP9zUgzZ8L//A88+CAcckjoVCIi2VNUnfvXX/vVL6ecAsuX+1Uxo0ersItI4Smazj2R8DchLVrku/a+fWG/gt+MWESKVcF37mvX+gum7dr5VTHxOAwZosIuIoWtoIv7mDF+r/WhQ/3eMHPmQPv2oVOJiNS8ghzLrFgB3bvDyJFw4okwfjycfHLoVCIiu09Bde7O+f3Vmzb1Bb1XL3jrLRV2ESk+BdO5L17sZ+vxOJxxhl+3fvTRoVOJiISR9537pk1+O95mzXyXPmCAXxmjwi4ixSyvO/fZs/2yxrIyOP98ePhhaNQodCoRkfDyunMfNizJggW9uf32JGPGqLCLiGyWt8U9mUzSv38p69ffSK9epbzxRjJ0JBGRnJG3xT2RSJBKpaioqCCVSpFIJEJHEhHJGXlb3GOxGJFIhJKSEiKRCLFYLHQkEZGckbcXVKPRKPF4nEQiQSwWIxqNho4kIpIz8ra4gy/wKuoiIt+Vt2MZERHZPhV3EZECpOIuIlKAVNxFRAqQiruISAFScRcRKUDmnAudATMrB5ZU89vrA6uzGCdblKtqlKvqcjWbclVNJrkOd8412NYXcqK4Z8LMypxzLUPn2JpyVY1yVV2uZlOuqqmpXBrLiIgUIBV3EZECVAjFfVDoANuhXFWjXFWXq9mUq2pqJFfez9xFROS7CqFzFxGRreRtcTezf5jZKjObGzrLlszsUDObbGbzzWyemV0dOhOAme1pZm+a2dvpXLeGzrQlMysxs5lm9nzoLJuZ2b/NbI6ZzTKzstB5NjOzemY20swWmtkCMwu+NaqZHZ3+77T5z+dmdk3oXABm9sf03/m5Zva0me0ZOhOAmV2dzjSvJv5b5e1YxszaAuuAx5xzzULn2czMGgINnXMzzOz7wHTgAufc/MC5DKjrnFtnZnWAqcDVzrk3QubazMyuBVoC+zjnfhI6D/jiDrR0zuXU2mgzGwb8yzk3xMwiwN7OubWBY33DzEqAZUAr51x171/JVpZG+L/rTZ1zX5vZCGCCc+7RwLmaAc8ApwIpYBLwO+fcomy9R9527s65KcCnoXNszTm33Dk3I/35F8ACIPjR3c5bl35YJ/0nJ/5lN7PGwHnAkNBZcp2Z7Qu0BYYCOOdSuVTY00qB90MX9i3UBvYys9rA3sDHgfMAHAtMc8595ZzbBLwK/DSbb5C3xT0fmFkT4CRgWuAowDejj1nAKuAl51xO5ALuA3oAlYFzbM0BL5rZdDPrGjpM2hFAOfBIeow1xMzqhg61lYuBp0OHAHDOLQPuAj4ElgOfOedeDJsKgLnAGWZ2gJntDZwLHJrNN1BxryFm9j1gFHCNc+7z0HkAnHMVzrnmQGPg1PSvhkGZ2U+AVc656aGzbMPpzrkWwDlAt/QoMLTaQAugv3PuJOBL4Lqwkb6VHhOdDzwbOguAme0HdMT/o3gIUNfMfhU2FTjnFgB3Ai/iRzKzgIpsvoeKew1Iz7RHAU8650aHzrO19K/xk4GzA0cBOA04Pz3ffgZob2ZPhI3kpbs+nHOrgOfw89HQlgJLt/itayS+2OeKc4AZzrmVoYOkdQA+cM6VO+c2AqOBNoEzAeCcG+qcO9k51xZYA7ybzZ+v4p5l6QuXQ4EFzrl7QufZzMwamFm99Od7AWcCC4OGApxz1zvnGjvnmuB/nX/FORe8szKzuukL4qTHHj/G/yodlHNuBfCRmR2dfqoUCHqxfiuXkCMjmbQPgdZmtnf6/5ul+OtgwZnZgemPh+Hn7U9l8+fn7QHZZvY0EAPqm9lS4Gbn3NCwqQDfiV4KzEnPtwH+6pybEC4SAA2BYemVDLWAEc65nFl2mIMOAp7z9YDawFPOuUlhI32jO/BkegSyGPhN4DzAN/8InglcETrLZs65aWY2EpgBbAJmkjt3qo4yswOAjUC3bF8Yz9ulkCIisn0ay4iIFCAVdxGRAqTiLiJSgFTcRUQKkIq7iEgBUnEXESlAKu4iIgVIxV1EpAD9P+FlYGw3dAW9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,model.predict(x),'b',x,y,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ec44449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "9.5시간 공부하면 102.15점 얻을 수 있다.\n"
     ]
    }
   ],
   "source": [
    "print(\"{0}시간 공부하면 {1:.2f}점 얻을 수 있다.\".format(9.5,*model.predict([9.5])[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
